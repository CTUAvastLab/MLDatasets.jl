var documenterSearchIndex = {"docs":
[{"location":"datasets/MNIST/#MNIST-1","page":"MNIST handwritten digits","title":"The MNIST database of handwritten digits","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"Description from the official website:","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.","category":"page"},{"location":"datasets/MNIST/#Contents-1","page":"MNIST handwritten digits","title":"Contents","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"Pages = [\"MNIST.md\"]\nDepth = 3","category":"page"},{"location":"datasets/MNIST/#Overview-1","page":"MNIST handwritten digits","title":"Overview","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"The MLDatasets.MNIST sub-module provides a programmatic interface to download, load, and work with the MNIST dataset of handwritten digits.","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = MNIST.traindata()\n\n# load full test set\ntest_x,  test_y  = MNIST.testdata()","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?MNIST.traindata).","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"Function Description\ndownload([dir]) Trigger (interactive) download of the dataset\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"This module also provides utility functions to make working with the MNIST dataset in Julia more convenient.","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"Function Description\nconvert2image(array) Convert the MNIST tensor/matrix to a colorant array","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"To visualize an image or a prediction we provide the function convert2image to convert the given MNIST horizontal-major tensor (or feature matrix) to a vertical-major Colorant array. The values are also color corrected according to the website's description, which means that the digits are black on a white background.","category":"page"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"julia> MNIST.convert2image(MNIST.traintensor(1)) # first training image\n28×28 Array{Gray{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/MNIST/#API-Documentation-1","page":"MNIST handwritten digits","title":"API Documentation","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"MNIST","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST","page":"MNIST handwritten digits","title":"MLDatasets.MNIST","text":"The MNIST database of handwritten digits\n\nAuthors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\nWebsite: http://yann.lecun.com/exdb/mnist/\n\nMNIST is a classic image-classification dataset that is often used in small-scale machine learning experiments. It contains 70,000 images of handwritten digits. Each observation is a 28x28 pixel gray-scale image that depicts a handwritten version of 1 of the 10 possible digits (0-9).\n\nInterface\n\nMNIST.traintensor, MNIST.trainlabels, MNIST.traindata\nMNIST.testtensor, MNIST.testlabels, MNIST.testdata\n\nUtilities\n\nMNIST.download\nMNIST.convert2image\n\n\n\n\n\n","category":"module"},{"location":"datasets/MNIST/#Trainingset-1","page":"MNIST handwritten digits","title":"Trainingset","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"MNIST.traintensor\nMNIST.trainlabels\nMNIST.traindata","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.traintensor","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturns the MNIST training images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 3D array (i.e. a Array{T,3}), in WHN format (width, height, #images).  For integer indices instead, a 2D array in WH format is returned.\n\njulia> MNIST.traintensor() # load all training images\n28×28×60000 Array{N0f8,3}:\n[...]\n\njulia> MNIST.traintensor(Float32, 1:3) # first three images as Float32\n28×28×3 Array{Float32,3}:\n[...]\n\nIf indices is an Integer, the single image is returned as Matrix{T}.\n\njulia> MNIST.traintensor(1) # load first training image\n28×28 Array{N0f8,2}:\n[...]\n\nYou can use the utility function convert2image to convert an MNIST array into a vertical-major Julia image with the corrected color values.\n\njulia> MNIST.convert2image(MNIST.traintensor(1)) # convert to column-major colorant array\n28×28 Array{Gray{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.trainlabels","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the MNIST trainset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the digit that they represent. If indices is omitted, all labels are returned.\n\njulia> MNIST.trainlabels() # full training set\n60000-element Array{Int64,1}:\n 5\n 0\n ⋮\n 6\n 8\n\njulia> MNIST.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 5\n 0\n 4\n\njulia> MNIST.trainlabels(1) # first label\n5\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.traindata","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> Tuple\n\nReturns the MNIST trainingset corresponding to the given indices as a two-element tuple. If indices is omitted the full trainingset is returned. The first element of three return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntrain_x, train_y = MNIST.traindata() # full datatset\ntrain_x, train_y = MNIST.traindata(2) # only second observation\ntrain_x, train_y = MNIST.traindata(dir=\"./MNIST\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at MNIST.traintensor and MNIST.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#Testset-1","page":"MNIST handwritten digits","title":"Testset","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"MNIST.testtensor\nMNIST.testlabels\nMNIST.testdata","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.testtensor","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturns the MNIST test images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 3D array (i.e. a Array{T,3}), in WHN format (width, height, #images).  For integer indices instead, a 2D array in WH format is returned.\n\njulia> MNIST.testtensor() # load all test images\n28×28×10000 Array{N0f8,3}:\n[...]\n\njulia> MNIST.testtensor(Float32, 1:3) # first three images as Float32\n28×28×3 Array{Float32,3}:\n[...]\n\nIf indices is an Integer, the single image is returned as Matrix{T}.\n\njulia> MNIST.testtensor(1) # load first test image\n28×28 Array{N0f8,2}:\n[...]\n\nYou can use the utility function convert2image to convert an MNIST array into a vertical-major Julia image with the corrected color values.\n\njulia> MNIST.convert2image(MNIST.testtensor(1)) # convert to column-major colorant array\n28×28 Array{Gray{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.testlabels","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the MNIST testset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the digit that they represent. If indices is omitted, all labels are returned.\n\njulia> MNIST.testlabels() # full test set\n10000-element Array{Int64,1}:\n 7\n 2\n ⋮\n 5\n 6\n\njulia> MNIST.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 7\n 2\n 1\n\njulia> MNIST.testlabels(1) # first label\n7\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.testdata","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> Tuple\n\nReturns the MNIST testset corresponding to the given indices as a two-element tuple. If indices is omitted the full testset is returned. The first element of three return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntest_x, test_y = MNIST.testdata() # full datatset\ntest_x, test_y = MNIST.testdata(2) # only second observation\ntest_x, test_y = MNIST.testdata(dir=\"./MNIST\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing MNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/MNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use MNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at MNIST.testtensor and MNIST.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#Utilities-1","page":"MNIST handwritten digits","title":"Utilities","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"MNIST.download\nMNIST.convert2image","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.download","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/MNIST\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#MLDatasets.MNIST.convert2image","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.convert2image","text":"convert2image(array) -> Array{Gray}\n\nConvert the given MNIST horizontal-major tensor (or feature matrix) to a vertical-major Colorant array. The values are also color corrected according to the website's description, which means that the digits are black on a white background.\n\njulia> MNIST.convert2image(MNIST.traintensor()) # full training dataset\n28×28×60000 Array{Gray{N0f8},3}:\n[...]\n\njulia> MNIST.convert2image(MNIST.traintensor(1)) # first training image\n28×28 Array{Gray{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"function"},{"location":"datasets/MNIST/#Reader-Sub-module-1","page":"MNIST handwritten digits","title":"Reader Sub-module","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"Modules = [MLDatasets.MNIST.Reader]\nOrder   = [:function]","category":"page"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimages-Tuple{IO,AbstractArray{T,1} where T,Integer,Integer}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readimages","text":"readimages(io::IO, indices::AbstractVector, nrows::Integer, ncols::Integer)\n\nReads the first nrows * ncols bytes for each image index in indices and stores them in a Array{UInt8,3} of size (nrows, ncols, length(indices)) in the same order as denoted by indices.\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimages-Tuple{IO,Any}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readimages","text":"readimages(file, [indices])\n\nReads the images denoted by indices from file. The given file can either be specified using an IO-stream or a string that denotes the fully qualified path. The conent of file is assumed to be in the MNIST image-file format, as it is described on the official homepage at http://yann.lecun.com/exdb/mnist/\n\nif indices is an Integer, the single image is returned as Matrix{UInt8} in horizontal major layout, which means that the first dimension denotes the pixel rows (x), and the second dimension denotes the pixel columns (y) of the image.\nif indices is a AbstractVector, the images are returned as a 3D array (i.e. a Array{UInt8,3}), in which the first dimension corresponds to the pixel rows (x) of the image, the second dimension to the pixel columns (y) of the image, and the third dimension denotes the index of the image.\nif indices is ommited all images are returned (as 3D array described above)\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimages-Tuple{IO,Integer,Integer,Integer}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readimages","text":"readimages(io::IO, index::Integer, nrows::Integer, ncols::Integer)\n\nJumps to the position of io where the bytes for the index'th image are located and reads the next nrows * ncols bytes. The read bytes are returned as a Matrix{UInt8} of size (nrows, ncols).\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabels-Tuple{AbstractString,Integer}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readlabels","text":"readlabels(file::AbstractString, [indices])\n\nReads the label denoted by indices from file. The given file is assumed to be in the MNIST label-file format, as it is described on the official homepage at http://yann.lecun.com/exdb/mnist/\n\nif indices is an Integer, the single label is returned as UInt8.\nif indices is a AbstractVector, the labels are returned as a Vector{UInt8}, length length(indices) in the same order as denoted by indices.\nif indices is ommited all all are returned (as Vector{UInt8} as described above)\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabels-Tuple{IO,AbstractArray{T,1} where T}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readlabels","text":"readlabels(io::IO, indices::AbstractVector)\n\nReads the byte for each label-index in indices and stores them in a Vector{UInt8} of length length(indices) in the same order as denoted by indices.\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabels-Tuple{IO,Integer}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readlabels","text":"readlabels(io::IO, index::Integer)\n\nJumps to the position of io where the byte for the index'th label is located and returns the byte at that position as UInt8\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimageheader-Tuple{AbstractString}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readimageheader","text":"readimageheader(file::AbstractString)\n\nOpens and reads the first four 32 bits values of file and returns them interpreted as an MNIST-image-file header\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readimageheader-Tuple{IO}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readimageheader","text":"readimageheader(io::IO)\n\nReads four 32 bit integers at the current position of io and interprets them as a MNIST-image-file header, which is described in detail in the table below\n\n        ║     First    │  Second  │  Third  │   Fourth\n════════╬══════════════╪══════════╪═════════╪════════════\noffset  ║         0000 │     0004 │    0008 │       0012\ndescr   ║ magic number │ # images │  # rows │  # columns\n\nThese four numbers are returned as a Tuple in the same storage order\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabelheader-Tuple{AbstractString}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readlabelheader","text":"readlabelheader(file::AbstractString)\n\nOpens and reads the first two 32 bits values of file and returns them interpreted as an MNIST-label-file header\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#MLDatasets.MNIST.Reader.readlabelheader-Tuple{IO}","page":"MNIST handwritten digits","title":"MLDatasets.MNIST.Reader.readlabelheader","text":"readlabelheader(io::IO)\n\nReads two 32 bit integers at the current position of io and interprets them as a MNIST-label-file header, which consists of a magic number and the total number of labels stored in the file. These two numbers are returned as a Tuple in the same storage order.\n\n\n\n\n\n","category":"method"},{"location":"datasets/MNIST/#References-1","page":"MNIST handwritten digits","title":"References","text":"","category":"section"},{"location":"datasets/MNIST/#","page":"MNIST handwritten digits","title":"MNIST handwritten digits","text":"Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\nWebsite: http://yann.lecun.com/exdb/mnist/\n[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998","category":"page"},{"location":"indices/#Functions-1","page":"Indices","title":"Functions","text":"","category":"section"},{"location":"indices/#","page":"Indices","title":"Indices","text":"Order   = [:function]","category":"page"},{"location":"indices/#Types-1","page":"Indices","title":"Types","text":"","category":"section"},{"location":"indices/#","page":"Indices","title":"Indices","text":"Order   = [:type]","category":"page"},{"location":"datasets/FashionMNIST/#FashionMNIST-1","page":"Fashion MNIST","title":"Fashion-MNIST","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Description from the official website","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.","category":"page"},{"location":"datasets/FashionMNIST/#Contents-1","page":"Fashion MNIST","title":"Contents","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Pages = [\"FashionMNIST.md\"]\nDepth = 3","category":"page"},{"location":"datasets/FashionMNIST/#Overview-1","page":"Fashion MNIST","title":"Overview","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"The MLDatasets.FashionMNIST sub-module provides a programmatic interface to download, load, and work with the Fashion-MNIST dataset.","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = FashionMNIST.traindata()\n\n# load full test set\ntest_x,  test_y  = FashionMNIST.testdata()","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?FashionMNIST.traindata).","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Function Description\ndownload([dir]) Trigger (interactive) download of the dataset\nclassnames() Return the class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"This module also provides utility functions to make working with the Fashion-MNIST dataset in Julia more convenient.","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Function Description\nconvert2image(array) Convert the Fashion-MNIST tensor/matrix to a colorant array","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"To visualize an image or a prediction we provide the function convert2image to convert the given Fashion-MNIST horizontal-major tensor (or feature matrix) to a vertical-major Colorant array. The values are also color corrected according to the website's description, which means that the digits are black on a white background.","category":"page"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"julia> FashionMNIST.convert2image(FashionMNIST.traintensor(1)) # first training image\n28×28 Array{Gray{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/FashionMNIST/#API-Documentation-1","page":"Fashion MNIST","title":"API Documentation","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"FashionMNIST","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST","text":"Fashion-MNIST\n\nAuthors: Han Xiao, Kashif Rasul, Roland Vollgraf\nWebsite: https://github.com/zalandoresearch/fashion-mnist\n\nFashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. It can serve as a drop-in replacement for MNIST.\n\nInterface\n\nFashionMNIST.traintensor, FashionMNIST.trainlabels, FashionMNIST.traindata\nFashionMNIST.testtensor, FashionMNIST.testlabels, FashionMNIST.testdata\n\nUtilities\n\nFashionMNIST.download\n\nAlso, the FashionMNIST module is re-exporting convert2image from the MNIST module.\n\n\n\n\n\n","category":"module"},{"location":"datasets/FashionMNIST/#Trainingset-1","page":"Fashion MNIST","title":"Trainingset","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"FashionMNIST.traintensor\nFashionMNIST.trainlabels\nFashionMNIST.traindata","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.traintensor","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nSame as MNIST.traintensor but for the FashionMNIST dataset.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.trainlabels","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the Fashion-MNIST trainset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see FashionMNIST.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> FashionMNIST.trainlabels() # full training set\n60000-element Array{Int64,1}:\n 9\n 0\n ⋮\n 0\n 5\n\njulia> FashionMNIST.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 9\n 0\n 0\n\njulia> y = FashionMNIST.trainlabels(1) # first label\n9\n\njulia> FashionMNIST.classnames()[y + 1] # corresponding name\n\"Ankle boot\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.traindata","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> images, labels\n\nSame as MNIST.traindata but for the FashionMNIST dataset.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at FashionMNIST.traintensor and FashionMNIST.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#Testset-1","page":"Fashion MNIST","title":"Testset","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"FashionMNIST.testtensor\nFashionMNIST.testlabels\nFashionMNIST.testdata","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.testtensor","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nSame as MNIST.testtensor but for the FashionMNIST dataset. ```\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.testlabels","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the Fashion-MNIST testset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the class-index that they represent (see FashionMNIST.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> FashionMNIST.testlabels() # full test set\n10000-element Array{Int64,1}:\n 9\n 2\n ⋮\n 1\n 5\n\njulia> FashionMNIST.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 9\n 2\n 1\n\njulia> y = FashionMNIST.testlabels(1) # first label\n9\n\njulia> FashionMNIST.classnames()[y + 1] # corresponding name\n\"Ankle boot\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.testdata","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> images, labels\n\nSame as MNIST.testdata but for the FashionMNIST dataset.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing FashionMNIST subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/FashionMNIST. In the case that dir does not yet exist, a download prompt will be triggered. You can also use FashionMNIST.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at FashionMNIST.testtensor and FashionMNIST.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#Utilities-1","page":"Fashion MNIST","title":"Utilities","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"FashionMNIST.download\nFashionMNIST.classnames","category":"page"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.download","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/FashionMNIST\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#MLDatasets.FashionMNIST.classnames","page":"Fashion MNIST","title":"MLDatasets.FashionMNIST.classnames","text":"classnames() -> Vector{String}\n\nReturn the 10 names for the Fashion-MNIST classes as a vector of strings.\n\n\n\n\n\n","category":"function"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Also, the FashionMNIST module is re-exporting convert2image from the MNIST module.","category":"page"},{"location":"datasets/FashionMNIST/#References-1","page":"Fashion MNIST","title":"References","text":"","category":"section"},{"location":"datasets/FashionMNIST/#","page":"Fashion MNIST","title":"Fashion MNIST","text":"Authors: Han Xiao, Kashif Rasul, Roland Vollgraf\nWebsite: https://github.com/zalandoresearch/fashion-mnist\n[Han Xiao et al. 2017] Han Xiao, Kashif Rasul, and Roland Vollgraf. \"Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.\" arXiv:1708.07747","category":"page"},{"location":"datasets/SVHN2/#SVHN2-1","page":"SVHN format 2","title":"The Street View House Numbers (SVHN) Dataset","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"Description from the official website:","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"About Format 2 (Cropped Digits):","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"All digits have been resized to a fixed resolution of 32-by-32 pixels. The original character bounding boxes are extended in the appropriate dimension to become square windows, so that resizing them to 32-by-32 pixels does not introduce aspect ratio distortions. Nevertheless this preprocessing introduces some distracting digits to the sides of the digit of interest.","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"note: Note\nFor non-commercial use only","category":"page"},{"location":"datasets/SVHN2/#Contents-1","page":"SVHN format 2","title":"Contents","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"Pages = [\"SVHN2.md\"]\nDepth = 3","category":"page"},{"location":"datasets/SVHN2/#Overview-1","page":"SVHN format 2","title":"Overview","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"The MLDatasets.SVHN2 sub-module provides a programmatic interface to download, load, and work with the SVHN2 dataset of handwritten digits.","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = SVHN2.traindata()\n\n# load full test set\ntest_x,  test_y  = SVHN2.testdata()\n\n# load additional train set\nextra_x, extra_y = SVHN2.extradata()","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?SVHN2.traindata).","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"Function Description\ndownload([dir]) Trigger interactive download of the dataset\nclassnames() Return the class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntestdata([T], [indices]; [dir]) Load images and labels of the test data\nextratensor([T], [indices]; [dir]) Load the extra images as an array of eltype T\nextralabels([indices]; [dir]) Load the labels for the extra training images\nextradata([T], [indices]; [dir]) Load images and labels of the extra training data","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"This module also provides utility functions to make working with the SVHN (format 2) dataset in Julia more convenient.","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"Function Description\nconvert2image(array) Convert the SVHN tensor/matrix to a colorant array","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"To visualize an image or a prediction we provide the function convert2image to convert the given SVHN2 horizontal-major tensor (or feature matrix) to a vertical-major Colorant array.","category":"page"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"julia> SVHN2.convert2image(SVHN2.traindata(1)[1]) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/SVHN2/#API-Documentation-1","page":"SVHN format 2","title":"API Documentation","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2","page":"SVHN format 2","title":"MLDatasets.SVHN2","text":"The Street View House Numbers (SVHN) Dataset\n\nAuthors: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\nWebsite: http://ufldl.stanford.edu/housenumbers\n\nSVHN was obtained from house numbers in Google Street View images. As such they are quite diverse in terms of orientation and image background. Similar to MNIST, SVHN has 10 classes (the digits 0-9), but unlike MNIST there is more data and the images are a little bigger (32x32 instead of 28x28) with an additional RGB color channel. The dataset is split up into three subsets: 73257 digits for training, 26032 digits for testing, and 531131 additional to use as extra training data.\n\nInterface\n\nSVHN2.traintensor, SVHN2.trainlabels, SVHN2.traindata\nSVHN2.testtensor, SVHN2.testlabels, SVHN2.testdata\nSVHN2.extratensor, SVHN2.extralabels, SVHN2.extradata\n\nUtilities\n\nSVHN2.download\nSVHN2.classnames\nSVHN2.convert2image\n\n\n\n\n\n","category":"module"},{"location":"datasets/SVHN2/#Trainingset-1","page":"SVHN format 2","title":"Trainingset","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.traintensor\nSVHN2.trainlabels\nSVHN2.traindata","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.traintensor","page":"SVHN format 2","title":"MLDatasets.SVHN2.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the SVHN training images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (y) of the image, the second dimension to the pixel rows (x) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> SVHN2.traintensor() # load all training images\n32×32×3×73257 Array{N0f8,4}:\n[...]\n\njulia> SVHN.traintensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3} in vertical-major layout, which means that the first dimension denotes the pixel columns (y), the second dimension denotes the pixel rows (x), and the third dimension the RGB color channels of the image.\n\njulia> SVHN2.traintensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nAs mentioned above, the color channel is encoded in the third dimension. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype.\n\njulia> SVHN2.convert2image(SVHN2.traintensor(1))\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.trainlabels","page":"SVHN format 2","title":"MLDatasets.SVHN2.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the SVHN training labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see SVHN2.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> SVHN2.trainlabels() # full training set\n73257-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.trainlabels(1) # first label\n[...]\n\njulia> SVHN2.classnames()[SVHN2.trainlabels(1)] # corresponding class\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.traindata","page":"SVHN format 2","title":"MLDatasets.SVHN2.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the SVHN trainset corresponding to the given indices as a two-element tuple. If indices is omitted the full trainset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype. The integer values of the labels correspond 1-to-1 the digit that they represent with the exception of 0 which is encoded as 10.\n\nNote that because of the nature of how the dataset is stored on disk, SVHN2.traindata will always load the full trainset, regardless of which observations are requested. In the case indices are provided by the user, it will simply result in a sub-setting. This option is just provided for convenience.\n\nimages, labels = SVHN2.traindata() # full dataset\nimages, labels = SVHN2.traindata(2) # only second observation\nimages, labels = SVHN2.traindata(dir=\"./SVHN\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#Testset-1","page":"SVHN format 2","title":"Testset","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.testtensor\nSVHN2.testlabels\nSVHN2.testdata","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.testtensor","page":"SVHN format 2","title":"MLDatasets.SVHN2.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the SVHN test images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (y) of the image, the second dimension to the pixel rows (x) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> SVHN2.testtensor() # load all test images\n32×32×3×26032 Array{N0f8,4}:\n[...]\n\njulia> SVHN.testtensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3} in vertical-major layout, which means that the first dimension denotes the pixel columns (y), the second dimension denotes the pixel rows (x), and the third dimension the RGB color channels of the image.\n\njulia> SVHN2.testtensor(1) # load first test image\n32×32×3 Array{N0f8,3}:\n[...]\n\nAs mentioned above, the color channel is encoded in the third dimension. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype.\n\njulia> SVHN2.convert2image(SVHN2.testtensor(1))\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.testlabels","page":"SVHN format 2","title":"MLDatasets.SVHN2.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the SVHN test labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see SVHN2.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> SVHN2.testlabels() # full test set\n26032-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.testlabels(1) # first label\n[...]\n\njulia> SVHN2.classnames()[SVHN2.testlabels(1)] # corresponding class\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.testdata","page":"SVHN format 2","title":"MLDatasets.SVHN2.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the SVHN testset corresponding to the given indices as a two-element tuple. If indices is omitted the full testset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype. The integer values of the labels correspond 1-to-1 the digit that they represent with the exception of 0 which is encoded as 10.\n\nNote that because of the nature of how the dataset is stored on disk, SVHN2.testdata will always load the full testset, regardless of which observations are requested. In the case indices are provided by the user, it will simply result in a sub-setting. This option is just provided for convenience.\n\nimages, labels = SVHN2.testdata() # full dataset\nimages, labels = SVHN2.testdata(2) # only second observation\nimages, labels = SVHN2.testdata(dir=\"./SVHN\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#Extraset-1","page":"SVHN format 2","title":"Extraset","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.extratensor\nSVHN2.extralabels\nSVHN2.extradata","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.extratensor","page":"SVHN format 2","title":"MLDatasets.SVHN2.extratensor","text":"extratensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the SVHN extra training images corresponding to the given indices as a multi-dimensional array of eltype T.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (y) of the image, the second dimension to the pixel rows (x) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> SVHN2.extratensor() # load all extra training images\n32×32×3×531131 Array{N0f8,4}:\n[...]\n\njulia> SVHN.extratensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3} in vertical-major layout, which means that the first dimension denotes the pixel columns (y), the second dimension denotes the pixel rows (x), and the third dimension the RGB color channels of the image.\n\njulia> SVHN2.extratensor(1) # load first extra training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nAs mentioned above, the color channel is encoded in the third dimension. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype.\n\njulia> SVHN2.convert2image(SVHN2.extratensor(1))\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.extralabels","page":"SVHN format 2","title":"MLDatasets.SVHN2.extralabels","text":"extralabels([indices]; [dir])\n\nReturns the SVHN extra training labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see SVHN2.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> SVHN2.extralabels() # full extra training set\n531131-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.extralabels(1:3) # first three labels\n3-element Array{Int64,1}:\n[...]\n\njulia> SVHN2.extralabels(1) # first label\n[...]\n\njulia> SVHN2.classnames()[SVHN2.extralabels(1)] # corresponding class\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.extradata","page":"SVHN format 2","title":"MLDatasets.SVHN2.extradata","text":"extradata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the SVHN extra trainset corresponding to the given indices as a two-element tuple. If indices is omitted the full extra trainset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the native vertical-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. You can use the utility function convert2image to convert an SVHN array into a Julia image with the appropriate RGB eltype. The integer values of the labels correspond 1-to-1 the digit that they represent with the exception of 0 which is encoded as 10.\n\nNote that because of the nature of how the dataset is stored on disk, SVHN2.extradata will always load the full extra trainset, regardless of which observations are requested. In the case indices are provided by the user, it will simply result in a sub-setting. This option is just provided for convenience.\n\nimages, labels = SVHN2.extradata() # full dataset\nimages, labels = SVHN2.extradata(2) # only second observation\nimages, labels = SVHN2.extradata(dir=\"./SVHN\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing SVHN2 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/SVHN2. In the case that dir does not yet exist, a download prompt will be triggered. You can also use SVHN2.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#Utilities-1","page":"SVHN format 2","title":"Utilities","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"SVHN2.download\nSVHN2.classnames\nSVHN2.convert2image","category":"page"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.download","page":"SVHN format 2","title":"MLDatasets.SVHN2.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/SVHN2\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAY_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.classnames","page":"SVHN format 2","title":"MLDatasets.SVHN2.classnames","text":"classnames() -> Vector{Int}\n\nReturn the 10 digits for the SVHN classes as a vector of integers.\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#MLDatasets.SVHN2.convert2image","page":"SVHN format 2","title":"MLDatasets.SVHN2.convert2image","text":"convert2image(array) -> Array{RGB}\n\nConvert the given SVHN tensor in WHCN format (or feature vector/matrix) to a RGB array in HWN format.\n\njulia> SVHN2.convert2image(SVHN2.traindata()[1]) # full training dataset\n32×32×50000 Array{RGB{N0f8},3}:\n[...]\n\njulia> SVHN2.convert2image(SVHN2.traindata(1)[1]) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"function"},{"location":"datasets/SVHN2/#References-1","page":"SVHN format 2","title":"References","text":"","category":"section"},{"location":"datasets/SVHN2/#","page":"SVHN format 2","title":"SVHN format 2","text":"Authors: Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng\nWebsite: http://ufldl.stanford.edu/housenumbers\n[Netzer et al., 2011] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng. \"Reading Digits in Natural Images with Unsupervised Feature Learning\" NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011","category":"page"},{"location":"LICENSE/#LICENSE-1","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/#","page":"LICENSE","title":"LICENSE","text":"using Markdown\nMarkdown.parse_file(joinpath(@__DIR__, \"..\", \"..\", \"LICENSE\"))","category":"page"},{"location":"datasets/CIFAR10/#CIFAR10-1","page":"CIFAR-10","title":"CIFAR-10","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"Description from the original website","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.","category":"page"},{"location":"datasets/CIFAR10/#Contents-1","page":"CIFAR-10","title":"Contents","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"Pages = [\"CIFAR10.md\"]\nDepth = 3","category":"page"},{"location":"datasets/CIFAR10/#Overview-1","page":"CIFAR-10","title":"Overview","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"The MLDatasets.CIFAR10 sub-module provides a programmatic interface to download, load, and work with the CIFAR-10 dataset.","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y = CIFAR10.traindata()\n\n# load full test set\ntest_x,  test_y  = CIFAR10.testdata()","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?CIFAR10.traindata).","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"Function Description\ndownload([dir]) Trigger interactive download of the dataset\nclassnames() Return the class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"This module also provides utility functions to make working with the CIFAR-10 dataset in Julia more convenient.","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"Function Description\nconvert2image(array) Convert the CIFAR-10 tensor/matrix to a colorant array","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"To visualize an image or a prediction we provide the function convert2image to convert the given CIFAR10 horizontal-major tensor (or feature matrix) to a vertical-major Colorant array.","category":"page"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"julia> CIFAR10.convert2image(CIFAR10.traintensor(1)) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/CIFAR10/#API-Documentation-1","page":"CIFAR-10","title":"API Documentation","text":"","category":"section"},{"location":"datasets/CIFAR10/#Trainingset-1","page":"CIFAR-10","title":"Trainingset","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"CIFAR10.traintensor\nCIFAR10.trainlabels\nCIFAR10.traindata","category":"page"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.traintensor","page":"CIFAR-10","title":"MLDatasets.CIFAR10.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-10 training images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR10.traindata instead.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}) in WHCN format (width, height, #channels, #images).  For integer indices instead, a 3D array in WHC format is returned.\n\njulia> CIFAR10.traintensor() # load all training images\n32×32×3×50000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR10.traintensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, a single image is returned as Array{T,3} array. \n\njulia> CIFAR10.traintensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-10 array into a horizontal-major Julia image with the appropriate RGB eltype.\n\njulia> CIFAR10.convert2image(CIFAR10.traintensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.trainlabels","page":"CIFAR-10","title":"MLDatasets.CIFAR10.trainlabels","text":"trainlabels([indices]; [dir])\n\nReturns the CIFAR-10 trainset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see CIFAR10.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> CIFAR10.trainlabels() # full training set\n50000-element Array{Int64,1}:\n 6\n 9\n ⋮\n 1\n 1\n\njulia> CIFAR10.trainlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 6\n 9\n 9\n\njulia> CIFAR10.trainlabels(1) # first label\n6\n\njulia> CIFAR10.classnames()[CIFAR10.trainlabels(1) + 1] # corresponding name\n\"frog\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.traindata","page":"CIFAR-10","title":"MLDatasets.CIFAR10.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the CIFAR-10 trainingset corresponding to the given indices as a two-element tuple. If indices is omitted the full trainingset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntrain_x, train_y = CIFAR10.traindata() # full datatset\ntrain_x, train_y = CIFAR10.traindata(2) # only second observation\ntrain_x, train_y = CIFAR10.traindata(dir=\"./CIFAR10\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR10.traintensor and CIFAR10.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#Testset-1","page":"CIFAR-10","title":"Testset","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"CIFAR10.testtensor\nCIFAR10.testlabels\nCIFAR10.testdata","category":"page"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.testtensor","page":"CIFAR-10","title":"MLDatasets.CIFAR10.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-10 test images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR10.testdata instead.\n\nImages are returned in horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}) in WHCN format (width, height, #channels, #images).  For integer indices instead, a 3D array in WHC format is returned.\n\njulia> CIFAR10.testtensor() # load all training images\n32×32×3×10000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR10.testtensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, a single image is returned as Array{T,3}.\n\njulia> CIFAR10.testtensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-10 array into a horizontal-major HW Julia image with the appropriate RGB eltype.\n\njulia> CIFAR10.convert2image(CIFAR10.testtensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.testlabels","page":"CIFAR-10","title":"MLDatasets.CIFAR10.testlabels","text":"testlabels([indices]; [dir])\n\nReturns the CIFAR-10 testset labels corresponding to the given indices as an Int or Vector{Int}. The values of the labels denote the zero-based class-index that they represent (see CIFAR10.classnames for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> CIFAR10.testlabels() # full training set\n10000-element Array{Int64,1}:\n 3\n 8\n ⋮\n 1\n 7\n\njulia> CIFAR10.testlabels(1:3) # first three labels\n3-element Array{Int64,1}:\n 3\n 8\n 8\n\njulia> CIFAR10.testlabels(1) # first label\n3\n\njulia> CIFAR10.classnames()[CIFAR10.testlabels(1) + 1] # corresponding name\n\"cat\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.testdata","page":"CIFAR-10","title":"MLDatasets.CIFAR10.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> images, labels\n\nReturns the CIFAR-10 testset corresponding to the given indices as a two-element tuple. If indices is omitted the full testset is returned. The first element of the return values will be the images as a multi-dimensional array, and the second element the corresponding labels as integers.\n\nThe image(s) is/are returned in the horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\ntest_x, test_y = CIFAR10.testdata() # full datatset\ntest_x, test_y = CIFAR10.testdata(2) # only second observation\ntest_x, test_y = CIFAR10.testdata(dir=\"./CIFAR10\") # custom folder\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR10 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR10. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR10.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR10.testtensor and CIFAR10.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#Utilities-1","page":"CIFAR-10","title":"Utilities","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"CIFAR10.download\nCIFAR10.classnames\nCIFAR10.convert2image","category":"page"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.download","page":"CIFAR-10","title":"MLDatasets.CIFAR10.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/CIFAR10\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.classnames","page":"CIFAR-10","title":"MLDatasets.CIFAR10.classnames","text":"classnames() -> Vector{String}\n\nReturn the 10 names for the CIFAR10 classes as a vector of strings.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#MLDatasets.CIFAR10.convert2image","page":"CIFAR-10","title":"MLDatasets.CIFAR10.convert2image","text":"convert2image(array) -> Array{RGB}\n\nConvert the given CIFAR-10 horizontal-major tensor WHCN (or feature vector/matrix) to a vertical-major HWN RGB array.\n\njulia> CIFAR10.convert2image(CIFAR10.traintensor()) # full training dataset\n32×32×50000 Array{RGB{N0f8},3}:\n[...]\n\njulia> CIFAR10.convert2image(CIFAR10.traintensor(1)) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR10/#References-1","page":"CIFAR-10","title":"References","text":"","category":"section"},{"location":"datasets/CIFAR10/#","page":"CIFAR-10","title":"CIFAR-10","text":"Authors: Alex Krizhevsky, Vinod Nair, Geoffrey Hinton\nWebsite: https://www.cs.toronto.edu/~kriz/cifar.html\n[Krizhevsky, 2009] Alex Krizhevsky. \"Learning Multiple Layers of Features from Tiny Images\", Tech Report, 2009.","category":"page"},{"location":"datasets/CIFAR100/#CIFAR100-1","page":"CIFAR-100","title":"CIFAR-100","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"Description from the original website","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).","category":"page"},{"location":"datasets/CIFAR100/#Contents-1","page":"CIFAR-100","title":"Contents","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"Pages = [\"CIFAR100.md\"]\nDepth = 3","category":"page"},{"location":"datasets/CIFAR100/#Overview-1","page":"CIFAR-100","title":"Overview","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"The MLDatasets.CIFAR100 sub-module provides a programmatic interface to download, load, and work with the CIFAR-100 dataset.","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"using MLDatasets\n\n# load full training set\ntrain_x, train_y_coarse, train_y_fine = CIFAR100.traindata()\n\n# load full test set\ntest_x, test_y_coarse, test_y_fine  = CIFAR100.testdata()","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"The provided functions also allow for optional arguments, such as the directory dir where the dataset is located, or the specific observation indices that one wants to work with. For more information on the interface take a look at the documentation (e.g. ?CIFAR100.traindata).","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"Function Description\ndownload([dir]) Trigger interactive download of the dataset\nclassnames_coarse(; [dir]) Return the 20 super-class names as a vector of strings\nclassnames_fine(; [dir]) Return the 100 class names as a vector of strings\ntraintensor([T], [indices]; [dir]) Load the training images as an array of eltype T\ntrainlabels([indices]; [dir]) Load the labels for the training images\ntesttensor([T], [indices]; [dir]) Load the test images as an array of eltype T\ntestlabels([indices]; [dir]) Load the labels for the test images\ntraindata([T], [indices]; [dir]) Load images and labels of the training data\ntestdata([T], [indices]; [dir]) Load images and labels of the test data","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"This module also provides utility functions to make working with the CIFAR-100 dataset in Julia more convenient.","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"Function Description\nconvert2image(array) Convert the CIFAR-100 tensor/matrix to a colorant array","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"To visualize an image or a prediction we provide the function convert2image to convert the given CIFAR-100 horizontal-major tensor (or feature matrix) to a vertical-major Colorant array.","category":"page"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"julia> CIFAR100.convert2image(CIFAR100.traintensor(1)) # first training image\n32×32 Array{RGB{N0f8},2}:\n[...]","category":"page"},{"location":"datasets/CIFAR100/#API-Documentation-1","page":"CIFAR-100","title":"API Documentation","text":"","category":"section"},{"location":"datasets/CIFAR100/#Trainingset-1","page":"CIFAR-100","title":"Trainingset","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"CIFAR100.traintensor\nCIFAR100.trainlabels\nCIFAR100.traindata","category":"page"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.traintensor","page":"CIFAR-100","title":"MLDatasets.CIFAR100.traintensor","text":"traintensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-100 training images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR100.traindata instead.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}) in WHCN format (width, height, #channels, #images).  For integer indices instead, a 3D array in WHC format is returned.\n\njulia> CIFAR100.traintensor() # load all training images\n32×32×3×50000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR100.traintensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3}.\n\njulia> CIFAR100.traintensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-100 array into a vertical-major Julia image with the appropriate RGB eltype.\n\njulia> CIFAR100.convert2image(CIFAR100.traintensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.trainlabels","page":"CIFAR-100","title":"MLDatasets.CIFAR100.trainlabels","text":"trainlabels([indices]; [dir]) -> Yc, Yf\n\nReturn the CIFAR-100 trainset labels (coarse and fine) corresponding to the given indices as a tuple of two Int or two Vector{Int}. The variables returned are the coarse label(s) (Yc) and the fine label(s) (Yf) respectively.\n\nYc, Yf = CIFAR100.trainlabels(); # full training set\n\nThe values of the labels denote the zero-based class-index that they represent (see CIFAR100.classnames_coarse and CIFAR100.classnames_fine for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> Yc, Yf = CIFAR100.trainlabels(1:3) # first three labels\n([11, 15, 4], [19, 29, 0])\n\njulia> yc, yf = CIFAR100.trainlabels(1) # first label\n(11, 19)\n\njulia> CIFAR100.classnames_coarse()[yc + 1] # corresponding superclass name\n\"large_omnivores_and_herbivores\"\n\njulia> CIFAR100.classnames_fine()[yf + 1] # corresponding class name\n\"cattle\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.traindata","page":"CIFAR-100","title":"MLDatasets.CIFAR100.traindata","text":"traindata([T = N0f8], [indices]; [dir]) -> X, Yc, Yf\n\nReturns the CIFAR-100 trainset corresponding to the given indices as a three-element tuple. If indices is omitted the full trainingset is returned. The first element of the three return values (X) will be the images as a multi-dimensional array, the second element (Yc) the corresponding coarse labels as integers, and the third element (Yf) the fine labels respectively.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\nX, Yc, Yf = CIFAR100.traindata() # full datatset\nX, Yc, Yf = CIFAR100.traindata(dir=\"./CIFAR100\") # custom folder\nx, yc, yf = CIFAR100.traindata(2) # only second observation\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR100.traintensor and CIFAR100.trainlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#Testset-1","page":"CIFAR-100","title":"Testset","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"CIFAR100.testtensor\nCIFAR100.testlabels\nCIFAR100.testdata","category":"page"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.testtensor","page":"CIFAR-100","title":"MLDatasets.CIFAR100.testtensor","text":"testtensor([T = N0f8], [indices]; [dir]) -> Array{T}\n\nReturn the CIFAR-100 test images corresponding to the given indices as a multi-dimensional array of eltype T. If the corresponding labels are required as well, it is recommended to use CIFAR100.testdata instead.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1.\n\nIf the parameter indices is omitted or an AbstractVector, the images are returned as a 4D array (i.e. a Array{T,4}), in which the first dimension corresponds to the pixel columns (x) of the image, the second dimension to the pixel rows (y) of the image, the third dimension the RGB color channels, and the fourth dimension denotes the index of the image.\n\njulia> CIFAR100.testtensor() # load all training images\n32×32×3×10000 Array{N0f8,4}:\n[...]\n\njulia> CIFAR100.testtensor(Float32, 1:3) # first three images as Float32\n32×32×3×3 Array{Float32,4}:\n[...]\n\nIf indices is an Integer, the single image is returned as Array{T,3}.\n\njulia> CIFAR100.testtensor(1) # load first training image\n32×32×3 Array{N0f8,3}:\n[...]\n\nYou can use the utility function convert2image to convert an CIFAR-100 array into a vertical-major Julia image with the appropriate RGB eltype.\n\njulia> CIFAR100.convert2image(CIFAR100.testtensor(1)) # convert to column-major colorant array\n32×32 Array{RGB{N0f8},2}:\n[...]\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.testlabels","page":"CIFAR-100","title":"MLDatasets.CIFAR100.testlabels","text":"testlabels([indices]; [dir]) -> Yc, Yf\n\nReturn the CIFAR-100 testset labels (coarse and fine) corresponding to the given indices as a tuple of two Int or two Vector{Int}. The variables returned are the coarse label(s) (Yc) and the fine label(s) (Yf) respectively.\n\nYc, Yf = CIFAR100.testlabels(); # full training set\n\nThe values of the labels denote the zero-based class-index that they represent (see CIFAR100.classnames_coarse and CIFAR100.classnames_fine for the corresponding names). If indices is omitted, all labels are returned.\n\njulia> Yc, Yf = CIFAR100.testlabels(1:3) # first three labels\n([10, 10, 0], [49, 33, 72])\n\njulia> yc, yf = CIFAR100.testlabels(1) # first label\n(10, 49)\n\njulia> CIFAR100.classnames_coarse()[yc + 1] # corresponding superclass name\n\"large_natural_outdoor_scenes\"\n\njulia> CIFAR100.classnames_fine()[yf + 1] # corresponding class name\n\"mountain\"\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.testdata","page":"CIFAR-100","title":"MLDatasets.CIFAR100.testdata","text":"testdata([T = N0f8], [indices]; [dir]) -> X, Yc, Yf\n\nReturns the CIFAR-100 testset corresponding to the given indices as a three-element tuple. If indices is omitted the full testset is returned. The first element of the three return values (X) will be the images as a multi-dimensional array, the second element (Yc) the corresponding coarse labels as integers, and the third element (Yf) the fine labels respectively.\n\nThe image(s) is/are returned in the native horizontal-major memory layout as a single numeric array of eltype T. If T <: Integer, then all values will be within 0 and 255, otherwise the values are scaled to be between 0 and 1. The integer values of the labels correspond 1-to-1 the digit that they represent.\n\nX, Yc, Yf = CIFAR100.testdata() # full datatset\nX, Yc, Yf = CIFAR100.testdata(dir=\"./CIFAR100\") # custom folder\nx, yc, yf = CIFAR100.testdata(2) # only second observation\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\nTake a look at CIFAR100.testtensor and CIFAR100.testlabels for more information.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#Utilities-1","page":"CIFAR-100","title":"Utilities","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"CIFAR100.download\nCIFAR100.classnames_coarse\nCIFAR100.classnames_fine","category":"page"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.download","page":"CIFAR-100","title":"MLDatasets.CIFAR100.download","text":"download([dir]; [i_accept_the_terms_of_use])\n\nTrigger the (interactive) download of the full dataset into \"dir\". If no dir is provided the dataset will be downloaded into \"~/.julia/datadeps/CIFAR100\".\n\nThis function will display an interactive dialog unless either the keyword parameter i_accept_the_terms_of_use or the environment variable DATADEPS_ALWAYS_ACCEPT is set to true. Note that using the data responsibly and respecting copyright/terms-of-use remains your responsibility.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.classnames_coarse","page":"CIFAR-100","title":"MLDatasets.CIFAR100.classnames_coarse","text":"classnames_coarse(; [dir]) -> Vector{String}\n\nReturn the 20 names for the CIFAR100 superclasses as a vector of strings. Note that these strings are read from the actual resource file.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#MLDatasets.CIFAR100.classnames_fine","page":"CIFAR-100","title":"MLDatasets.CIFAR100.classnames_fine","text":"classnames_fine(; [dir]) -> Vector{String}\n\nReturn the 100 names for the CIFAR100 classes as a vector of strings. Note that these strings are read from the actual resource file.\n\nThe corresponding resource file(s) of the dataset is/are expected to be located in the specified directory dir. If dir is omitted the directories in DataDeps.default_loadpath will be searched for an existing CIFAR100 subfolder. In case no such subfolder is found, dir will default to ~/.julia/datadeps/CIFAR100. In the case that dir does not yet exist, a download prompt will be triggered. You can also use CIFAR100.download([dir]) explicitly for pre-downloading (or re-downloading) the dataset. Please take a look at the documentation of the package DataDeps.jl for more detail and configuration options.\n\n\n\n\n\n","category":"function"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"See also CIFAR10.convert2image.","category":"page"},{"location":"datasets/CIFAR100/#References-1","page":"CIFAR-100","title":"References","text":"","category":"section"},{"location":"datasets/CIFAR100/#","page":"CIFAR-100","title":"CIFAR-100","text":"Authors: Alex Krizhevsky, Vinod Nair, Geoffrey Hinton\nWebsite: https://www.cs.toronto.edu/~kriz/cifar.html\n[Krizhevsky, 2009] Alex Krizhevsky. \"Learning Multiple Layers of Features from Tiny Images\", Tech Report, 2009.","category":"page"},{"location":"#MLDatasets.jl's-Documentation-1","page":"Home","title":"MLDatasets.jl's Documentation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This package represents a community effort to provide a common interface for accessing common Machine Learning (ML) datasets. In contrast to other data-related Julia packages, the focus of MLDatasets.jl is specifically on downloading, unpacking, and accessing benchmark dataset. Functionality for the purpose of data processing or visualization is only provided to a degree that is special to some dataset.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This package is a part of the JuliaML ecosystem. Its functionality is build on top of the package DataDeps.jl.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"To install MLDatasets.jl, start up Julia and type the following code snippet into the REPL. It makes use of the native Julia package manger.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Pkg.add(\"MLDatasets\")","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Additionally, for example if you encounter any sudden issues, or in the case you would like to contribute to the package, you can manually choose to be on the latest (untagged) version.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Pkg.checkout(\"MLDatasets\")","category":"page"},{"location":"#Basic-Usage-1","page":"Home","title":"Basic Usage","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The way MLDatasets.jl is organized is that each dataset has its own dedicated sub-module. Where possible, those sub-module share a common interface for interacting with the datasets. For example you can load the training set and the test set of the MNIST database of handwritten digits using the following commands:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using MLDatasets\n\ntrain_x, train_y = MNIST.traindata()\ntest_x,  test_y  = MNIST.testdata()","category":"page"},{"location":"#","page":"Home","title":"Home","text":"To load the data the package looks for the necessary files in various locations (see DataDeps.jl for more information on how to configure such defaults). If the data can't be found in any of those locations, then the package will trigger a download dialog to ~/.julia/datadeps/MNIST. To overwrite this on a case by case basis, it is possible to specify a data directory directly in traindata(dir = <directory>) and testdata(dir = <directory>).","category":"page"},{"location":"#Available-Datasets-1","page":"Home","title":"Available Datasets","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Each dataset has its own dedicated sub-module. As such, it makes sense to document their functionality similarly distributed. Find below a list of available datasets and their documentation.","category":"page"},{"location":"#Image-Classification-1","page":"Home","title":"Image Classification","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This package provides a variety of common benchmark datasets for the purpose of image classification.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Dataset Classes traintensor trainlabels testtensor testlabels\nMNIST 10 28x28x60000 60000 28x28x10000 10000\nFashionMNIST 10 28x28x60000 60000 28x28x10000 10000\nCIFAR-10 10 32x32x3x50000 50000 32x32x3x10000 10000\nCIFAR-100 100 (20) 32x32x3x50000 50000 (x2) 32x32x3x10000 10000 (x2)\nSVHN-2 (*) 10 32x32x3x73257 73257 32x32x3x26032 26032","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(*) Note that the SVHN-2 dataset provides an additional 531131 observations aside from the training- and testset","category":"page"},{"location":"#Misc.-Datasets-1","page":"Home","title":"Misc. Datasets","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Dataset Classes traintensor trainlabels testtensor testlabels\nIris 3 4x150 150 - -","category":"page"},{"location":"#Language-Modeling-1","page":"Home","title":"Language Modeling","text":"","category":"section"},{"location":"#PTBLM-1","page":"Home","title":"PTBLM","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The PTBLM dataset consists of Penn Treebank sentences for language modeling, available from tomsercu/lstm. The unknown words are replaced with <unk> so that the total vocabulary size becomes 10000.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This is the first sentence of the PTBLM dataset.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"x, y = PTBLM.traindata()\n\nx[1]\n> [\"no\", \"it\", \"was\", \"n't\", \"black\", \"monday\"]\ny[1]\n> [\"it\", \"was\", \"n't\", \"black\", \"monday\", \"<eos>\"]","category":"page"},{"location":"#","page":"Home","title":"Home","text":"where MLDataset adds the special word: <eos> to the end of y.","category":"page"},{"location":"#Text-Analysis-(POS-Tagging,-Parsing)-1","page":"Home","title":"Text Analysis (POS-Tagging, Parsing)","text":"","category":"section"},{"location":"#UD-English-1","page":"Home","title":"UD English","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The UD_English Universal Dependencies English Web Treebank dataset is an annotated corpus of morphological features, POS-tags and syntactic trees. The dataset follows CoNLL-style format.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"traindata = UD_English.traindata()\ndevdata = UD_English.devdata()\ntestdata = UD_English.devdata()","category":"page"},{"location":"#Data-Size-1","page":"Home","title":"Data Size","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"|    | Train x | Train y | Test x | Test y | |:–:|:–––-:|:–––-:|:–––:|:–––:| | PTBLM | 42068 | 42068 | 3761 | 3761 | | UD_English | 12543 | - | 2077 | - |","category":"page"},{"location":"#Index-1","page":"Home","title":"Index","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\"indices.md\"]","category":"page"}]
}
